{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd2cbe9-f61f-49dc-810e-c0616b57bd65",
   "metadata": {},
   "source": [
    "# 3. Vision Transformer ViT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65eb1edf-90df-46e1-97cd-f630eab10967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMW 1 Series 2019.jpg\n",
      "BMW 2 Series Active Tourer 2022.jpg\n",
      "BMW 2 Series Gran Coupe 2020.jpg\n",
      "BMW 3 Series 2014.jpg\n",
      "BMW 4 Series 2015.jpg\n",
      "BMW 4 Series Convertible 2021.jpg\n",
      "BMW 5 Series 2017.jpg\n",
      "BMW 6 Series 2017.jpg\n",
      "BMW 7 Series 2015.jpg\n",
      "BMW 7 Series 2023.jpg\n",
      "BMW 8 Series 2018.jpg\n",
      "BMW i3 2016.jpg\n",
      "BMW i4 2022.jpg\n",
      "BMW i7 2023.jpg\n",
      "BMW i8 2014.jpg\n",
      "BMW iX 2021.jpg\n",
      "BMW iX3 2020.jpg\n",
      "BMW M2 2016.jpg\n",
      "BMW M8 2019.jpg\n",
      "BMW X1 2016.jpg\n",
      "BMW X2 2018.jpg\n",
      "BMW X3 2017.jpg\n",
      "BMW X3 M 2022.jpg\n",
      "BMW X4 2021.jpg\n",
      "BMW X5 2014.jpg\n",
      "BMW X5 M 2020.jpg\n",
      "BMW X6 2015.jpg\n",
      "BMW X7 2019.jpg\n",
      "BMW XM 2023.jpg\n",
      "BMW Z4 2018.jpg\n",
      "Buick Enclave 2017.jpg\n",
      "Buick Encore 2017.jpg\n",
      "Buick Envision 2023.jpg\n",
      "BYD Dolphin 2023.jpg\n",
      "BYD e3 2019.jpg\n",
      "BYD e3 DM-i 2021.jpg\n",
      "BYD e5 2018.jpg\n",
      "BYD e6 2018.jpg\n",
      "BYD Han 2020.jpg\n",
      "BYD Qin 2014.jpg\n",
      "BYD Qin Plus 2022.jpg\n",
      "BYD Qin Pro 2022.jpg\n",
      "BYD Song 2016.jpg\n",
      "BYD Song Max 2019.jpg\n",
      "BYD Song Plus 2023.jpg\n",
      "BYD Song Pro 2020.jpg\n",
      "BYD Tang 2015.jpg\n",
      "BYD Tang DM-i 2021.jpg\n",
      "BYD Yuan 2017.jpg\n",
      "Cadillac CT5 2021.jpg\n",
      "Cadillac Escalade 2016.jpg\n",
      "Cadillac XT5 2018.jpg\n",
      "Cadillac XT6 2014.jpg\n",
      "Chevrolet Camaro 2015.jpg\n",
      "Chevrolet Impala 2017.jpg\n",
      "Chevrolet Malibu 2014.jpg\n",
      "Chevrolet Silverado 2015.jpg\n",
      "Chevrolet Trailblazer 2022.jpg\n",
      "Chevrolet Traverse 2019.jpg\n",
      "Ferrari 296 GTB 2022.jpg\n",
      "Ferrari 458 Italia 2014.jpg\n",
      "Ferrari 488 GTB 2015.jpg\n",
      "Ferrari 488 Pista 2019.jpg\n",
      "Ferrari 488 Pista Spider 2019.jpg\n",
      "Ferrari 488 Spider 2019.jpg\n",
      "Ferrari 812 GTS 2019.jpg\n",
      "Ferrari 812 Superfast 2017.jpg\n",
      "Ferrari California T 2015.jpg\n",
      "Ferrari F12 Berlinetta 2016.jpg\n",
      "Ferrari F8 Spider 2019.jpg\n",
      "Ferrari F8 Tributo 2021.jpg\n",
      "Ferrari F8 Tributo 2022.jpg\n",
      "Ferrari Portofino 2017.jpg\n",
      "Ferrari Portofino M 2021.jpg\n",
      "Ferrari Roma 2020.jpg\n",
      "Ferrari SF90 Spider 2021.jpg\n",
      "Ferrari SF90 Stradale 2020.jpg\n",
      "Ferrari SF90 Stradale Assetto Fiorano 2021.jpg\n",
      "Ford Bronco 2020.jpg\n",
      "Ford EcoSport 2018.jpg\n",
      "Ford Edge 2018.jpg\n",
      "Ford Escape 2016.jpg\n",
      "Ford Expedition 2023.jpg\n",
      "Ford Explorer 2017.jpg\n",
      "Ford F-150 2021.jpg\n",
      "Ford Fiesta 2014.jpg\n",
      "Ford Focus 2015.jpg\n",
      "Ford Fusion 2015.jpg\n",
      "Ford Fusion Hybrid 2022.jpg\n",
      "Ford Mach-E 2021.jpg\n",
      "Ford Maverick 2022.jpg\n",
      "Ford Mustang 2017.jpg\n",
      "Ford Mustang Mach 1 2023.jpg\n",
      "Ford Puma 2020.jpg\n",
      "Ford Ranger 2019.jpg\n",
      "Ford Transit 2019.jpg\n",
      "Geely Binrui 2014.jpg\n",
      "Geely Binrui 2019.jpg\n",
      "Geely Binyue 2017.jpg\n",
      "Geely Boyue 2017.jpg\n",
      "Geely Coolray 2020.jpg\n",
      "Geely Emgrand EC7 2014.jpg\n",
      "Geely Emgrand EC8 2015.jpg\n",
      "Geely Emgrand GL 2018.jpg\n",
      "Geely Emgrand GS 2016.jpg\n",
      "Geely Emgrand X7 2015.jpg\n",
      "Geely Haoyue 2021.jpg\n",
      "Geely Icon 2023.jpg\n",
      "Geely Vision Starburst 2022.jpg\n",
      "Geely Yuanjing X3 2016.jpg\n",
      "GMC Acadia 2016.jpg\n",
      "GMC Sierra 2015.jpg\n",
      "GMC Terrain 2020.jpg\n",
      "Great Wall Coolbear 2016.jpg\n",
      "Great Wall Haval H2 2015.jpg\n",
      "Great Wall Haval H5 2022.jpg\n",
      "Great Wall Haval H6 2014.jpg\n",
      "Great Wall Haval H7 2019.jpg\n",
      "Great Wall Haval H9 2017.jpg\n",
      "Great Wall Ora Black Cat 2023.jpg\n",
      "Great Wall Ora Cyber Cat 2014.jpg\n",
      "Great Wall Ora Haomao 2016.jpg\n",
      "Great Wall Ora Punk Cat 2015.jpg\n",
      "Great Wall Ora R2 2017.jpg\n",
      "Great Wall Pao 2021.jpg\n",
      "Great Wall Tank 300 2020.jpg\n",
      "Great Wall Voleex C20R 2017.jpg\n",
      "Great Wall Wingle 5 2015.jpg\n",
      "Great Wall Wingle 7 2018.jpg\n",
      "Honda Accord 2014.jpg\n",
      "Honda Accord Hybrid 2021.jpg\n",
      "Honda City 2018.jpg\n",
      "Honda Civic 2015.jpg\n",
      "Honda Civic Type R 2022.jpg\n",
      "Honda Clarity 2021.jpg\n",
      "Honda CR-V 2015.jpg\n",
      "Honda CR-V Hybrid 2020.jpg\n",
      "Honda Fit 2016.jpg\n",
      "Honda HR-V 2017.jpg\n",
      "Honda Insight 2019.jpg\n",
      "Honda Odyssey 2019.jpg\n",
      "Honda Passport 2019.jpg\n",
      "Honda Pilot 2017.jpg\n",
      "Honda Ridgeline 2020.jpg\n",
      "Hyundai Accent 2017.jpg\n",
      "Hyundai Elantra 2015.jpg\n",
      "Hyundai Elantra N 2023.jpg\n",
      "Hyundai Genesis G70 2016.jpg\n",
      "Hyundai Ioniq 5 2021.jpg\n",
      "Hyundai Ioniq Hybrid 2017.jpg\n",
      "Hyundai Kona 2017.jpg\n",
      "Hyundai Palisade 2020.jpg\n",
      "Hyundai Santa Cruz 2022.jpg\n",
      "Hyundai Santa Fe 2016.jpg\n",
      "Hyundai Sonata 2014.jpg\n",
      "Hyundai Sonata Hybrid 2014.jpg\n",
      "Hyundai Tucson 2015.jpg\n",
      "Hyundai Veloster 2018.jpg\n",
      "Hyundai Veloster N 2015.jpg\n",
      "Hyundai Venue 2019.jpg\n",
      "Isuzu D-Max 2014.jpg\n",
      "Isuzu D-Max Hi-Lander 2014.jpg\n",
      "Isuzu D-Max Hi-Lander 2023.jpg\n",
      "Isuzu D-Max V-Cross 2019.jpg\n",
      "Isuzu ELF 2018.jpg\n",
      "Isuzu F-Series 2016.jpg\n",
      "Isuzu Forward 2017.jpg\n",
      "Isuzu FTR 2021.jpg\n",
      "Isuzu Giga 2020.jpg\n",
      "Isuzu MU-X 2015.jpg\n",
      "Isuzu MU-X 2022.jpg\n",
      "Isuzu N-Series 2017.jpg\n",
      "Isuzu NPR 2015.jpg\n",
      "Li ONE 2020.jpg\n",
      "Li ONE 2022.jpg\n",
      "Li Xiang ONE 2021.jpg\n",
      "Li Xiang ONE 2023.jpg\n",
      "Lucid Air 2021.jpg\n",
      "Lucid Air Pure 2022.jpg\n",
      "Lucid Air Touring 2023.jpg\n",
      "Mahindra Alturas G4 2019.jpg\n",
      "Mahindra Bolero 2016.jpg\n",
      "Mahindra Bolero Neo 2022.jpg\n",
      "Mahindra e2o Plus 2017.jpg\n",
      "Mahindra KUV100 2017.jpg\n",
      "Mahindra Marazzo 2018.jpg\n",
      "Mahindra NuvoSport 2016.jpg\n",
      "Mahindra Scorpio 2015.jpg\n",
      "Mahindra Thar 2015.jpg\n",
      "Mahindra Thar 2021.jpg\n",
      "Mahindra TUV300 2017.jpg\n",
      "Mahindra Verito 2015.jpg\n",
      "Mahindra XUV300 2020.jpg\n",
      "Mahindra XUV400 2014.jpg\n",
      "Mahindra XUV500 2014.jpg\n",
      "Mahindra XUV700 2023.jpg\n",
      "Mazda CX-20 2014.jpg\n",
      "Mazda CX-3 2017.jpg\n",
      "Mazda CX-30 2020.jpg\n",
      "Mazda CX-4 2016.jpg\n",
      "Mazda CX-5 2015.jpg\n",
      "Mazda CX-50 2023.jpg\n",
      "Mazda CX-9 2017.jpg\n",
      "Mazda MX-30 2021.jpg\n",
      "Mazda MX-5 Miata 2016.jpg\n",
      "Mazda MX-5 Miata RF 2018.jpg\n",
      "Mazda MX-6 2017.jpg\n",
      "Mazda3 2014.jpg\n",
      "Mazda3 Hatchback 2019.jpg\n",
      "Mazda5 2015.jpg\n",
      "Mazda6 2015.jpg\n",
      "Mazda6 Turbo 2022.jpg\n",
      "Mercedes-Benz A-Class 2020.jpg\n",
      "Mercedes-Benz AMG GT 2023.jpg\n",
      "Mercedes-Benz C-Class 2014.jpg\n",
      "Mercedes-Benz CLA Coupe 2019.jpg\n",
      "Mercedes-Benz CLA-Class 2018.jpg\n",
      "Mercedes-Benz CLS-Class 2023.jpg\n",
      "Mercedes-Benz E-Class 2015.jpg\n",
      "Mercedes-Benz EQC 2020.jpg\n",
      "Mercedes-Benz EQS 2021.jpg\n",
      "Mercedes-Benz G-Class 2019.jpg\n",
      "Mercedes-Benz GLA-Class 2017.jpg\n",
      "Mercedes-Benz GLA-Class 2022.jpg\n",
      "Mercedes-Benz GLB-Class 2019.jpg\n",
      "Mercedes-Benz GLC Coupe 2019.jpg\n",
      "Mercedes-Benz GLC-Class 2016.jpg\n",
      "Mercedes-Benz GLE-Class 2017.jpg\n",
      "Mercedes-Benz GLS-Class 2022.jpg\n",
      "Mercedes-Benz S-Class 2015.jpg\n",
      "Mercedes-Benz S-Class 2021.jpg\n",
      "Mercedes-Benz SL-Class 2021.jpg\n",
      "NIO EC6 2020.jpg\n",
      "NIO EP9 2017.jpg\n",
      "NIO ES5 2023.jpg\n",
      "NIO ES6 2019.jpg\n",
      "NIO ES8 2018.jpg\n",
      "NIO ES9 2022.jpg\n",
      "NIO ET7 2021.jpg\n",
      "NIO Eve 2016.jpg\n",
      "Nissan 370Z 2017.jpg\n",
      "Nissan Altima 2014.jpg\n",
      "Nissan Ariya 2021.jpg\n",
      "Nissan GT-R 2014.jpg\n",
      "Nissan Juke 2015.jpg\n",
      "Nissan Kicks 2020.jpg\n",
      "Nissan Maxima 2017.jpg\n",
      "Nissan Murano 2017.jpg\n",
      "Nissan NV200 2016.jpg\n",
      "Nissan Pathfinder 2016.jpg\n",
      "Nissan Rogue 2015.jpg\n",
      "Nissan Sentra 2015.jpg\n",
      "Nissan Terra 2023.jpg\n",
      "Nissan Titan 2018.jpg\n",
      "Nissan Versa 2019.jpg\n",
      "Nissan Z 2022.jpg\n",
      "Polaris General 1000 2019.jpg\n",
      "Polaris Indy 600 2018.jpg\n",
      "Polaris Ranger EV 2020.jpg\n",
      "Polaris Ranger XP 900 2014.jpg\n",
      "Polaris RZR Pro XP 2022.jpg\n",
      "Polaris RZR XP 1000 2015.jpg\n",
      "Polaris Slingshot 2017.jpg\n",
      "Polaris Slingshot R 2023.jpg\n",
      "Polaris Sportsman 570 2016.jpg\n",
      "Polaris Sportsman XP 1000 S 2021.jpg\n",
      "Polestar 1 2019.jpg\n",
      "Polestar 2 2020.jpg\n",
      "Polestar 3 2022.jpg\n",
      "Polestar 4 2023.jpg\n",
      "Renault Arkana 2020.jpg\n",
      "Renault Captur 2015.jpg\n",
      "Renault Captur II 2021.jpg\n",
      "Renault Clio 2014.jpg\n",
      "Renault Fluence 2015.jpg\n",
      "Renault Kadjar 2016.jpg\n",
      "Renault Koleos 2017.jpg\n",
      "Renault Laguna 2014.jpg\n",
      "Renault Megane 2015.jpg\n",
      "Renault Megane E-Tech Electric 2022.jpg\n",
      "Renault Scenic 2017.jpg\n",
      "Renault Talisman 2023.jpg\n",
      "Renault Twingo 2018.jpg\n",
      "Renault Twizy 2017.jpg\n",
      "Renault Wind 2016.jpg\n",
      "Renault Zoe 2019.jpg\n",
      "Rivian Amazon Delivery Van.jpg\n",
      "Rivian R1S.jpg\n",
      "Rivian R1T.jpg\n",
      "Rivian R2.jpg\n",
      "Stellantis 200X.jpg\n",
      "Stellantis Horizon.jpg\n",
      "Stellantis Nova.jpg\n",
      "Stellantis Strada.jpg\n",
      "Stellantis Voyager.jpg\n",
      "Subaru Ascent 2019.jpg\n",
      "Subaru Baja 2017.jpg\n",
      "Subaru BRZ 2018.jpg\n",
      "Subaru Crosstrek 2016.jpg\n",
      "Subaru Crosstrek Hybrid 2020.jpg\n",
      "Subaru Exiga 2016.jpg\n",
      "Subaru Forester 2015.jpg\n",
      "Subaru Impreza 2014.jpg\n",
      "Subaru Legacy 2017.jpg\n",
      "Subaru Levorg 2015.jpg\n",
      "Subaru Outback 2015.jpg\n",
      "Subaru Outback Wilderness 2021.jpg\n",
      "Subaru Solterra 2023.jpg\n",
      "Subaru WRX 2017.jpg\n",
      "Subaru WRX STI 2022.jpg\n",
      "Subaru XV 2014.jpg\n",
      "Suzuki Across 2020.jpg\n",
      "Suzuki Baleno 2016.jpg\n",
      "Suzuki Carry 2016.jpg\n",
      "Suzuki Every 2015.jpg\n",
      "Suzuki Ignis 2017.jpg\n",
      "Suzuki Ignis Hybrid 2023.jpg\n",
      "Suzuki Jimny 2015.jpg\n",
      "Suzuki Jimny Sierra 2018.jpg\n",
      "Suzuki S-Cross 2017.jpg\n",
      "Suzuki Solio 2022.jpg\n",
      "Suzuki Spacia 2014.jpg\n",
      "Suzuki Swace 2021.jpg\n",
      "Suzuki Swift 2014.jpg\n",
      "Suzuki Swift Sport 2019.jpg\n",
      "Suzuki Vitara 2015.jpg\n",
      "Suzuki Wagon R 2017.jpg\n",
      "Tesla Cybertruck 2023.jpg\n",
      "Tesla Model 3 2017.jpg\n",
      "Tesla Model 3 2021.jpg\n",
      "Tesla Model 3 Long Range 2018.jpg\n",
      "Tesla Model 3 Performance 2018.jpg\n",
      "Tesla Model 3 Standard Range Plus 2019.jpg\n",
      "Tesla Model S 100D 2017.jpg\n",
      "Tesla Model S 2014.jpg\n",
      "Tesla Model S Long Range 2019.jpg\n",
      "Tesla Model S P90D 2015.jpg\n",
      "Tesla Model S Plaid 2021.jpg\n",
      "Tesla Model X 2015.jpg\n",
      "Tesla Model X Long Range 2019.jpg\n",
      "Tesla Model X P90D 2016.jpg\n",
      "Tesla Model X Plaid 2022.jpg\n",
      "Tesla Model Y 2020.jpg\n",
      "Tesla Model Y Long Range 2023.jpg\n",
      "Tesla Model Y Standard Range 2021.jpg\n",
      "Tesla Roadster 2020.jpg\n",
      "Tesla Semi 2022.jpg\n",
      "Toyota 4Runner 2020.jpg\n",
      "Toyota Avalon 2021.jpg\n",
      "Toyota Camry 2015.jpg\n",
      "Toyota Camry Hybrid 2019.jpg\n",
      "Toyota Corolla 2014.jpg\n",
      "Toyota Corolla Cross 2021.jpg\n",
      "Toyota Corolla Hatchback 2019.jpg\n",
      "Toyota Corolla Hybrid 2019.jpg\n",
      "Toyota Highlander 2017.jpg\n",
      "Toyota Prius 2015.jpg\n",
      "Toyota Prius C 2022.jpg\n",
      "Toyota Prius Prime 2019.jpg\n",
      "Toyota RAV4 2016.jpg\n",
      "Toyota RAV4 Hybrid 2019.jpg\n",
      "Toyota Sienna 2022.jpg\n",
      "Toyota Supra 2020.jpg\n",
      "Toyota Tacoma 2017.jpg\n",
      "Toyota Tacoma TRD Pro 2021.jpg\n",
      "Toyota Tundra 2023.jpg\n",
      "Toyota Venza 2023.jpg\n",
      "VinFast Fadil 2019.jpg\n",
      "VinFast Lux A2.0 2019.jpg\n",
      "VinFast Lux SA2.0 2020.jpg\n",
      "VinFast Lux SA2.0 GT 2021.jpg\n",
      "VinFast President 2022.jpg\n",
      "VinFast VF e34 2023.jpg\n",
      "Volkswagen Amarok 2022.jpg\n",
      "Volkswagen Arteon 2018.jpg\n",
      "Volkswagen Golf 2014.jpg\n",
      "Volkswagen Golf 8 2020.jpg\n",
      "Volkswagen ID. Buzz 2021.jpg\n",
      "Volkswagen ID.3 2020.jpg\n",
      "Volkswagen ID.4 2020.jpg\n",
      "Volkswagen ID.5 2023.jpg\n",
      "Volkswagen ID.6 2023.jpg\n",
      "Volkswagen Multivan 2022.jpg\n",
      "Volkswagen Passat 2015.jpg\n",
      "Volkswagen Polo 2015.jpg\n",
      "Volkswagen Polo GTI 2021.jpg\n",
      "Volkswagen T-Cross 2019.jpg\n",
      "Volkswagen T-Roc 2017.jpg\n",
      "Volkswagen Taigo 2023.jpg\n",
      "Volkswagen Tiguan 2016.jpg\n",
      "Volkswagen Tiguan Allspace 2019.jpg\n",
      "Volkswagen Touareg 2017.jpg\n",
      "Volvo C30 2014.jpg\n",
      "Volvo C40 Recharge 2022.jpg\n",
      "Volvo S60 2014.jpg\n",
      "Volvo S60 2019.jpg\n",
      "Volvo S80 2016.jpg\n",
      "Volvo S90 2017.jpg\n",
      "Volvo V40 2015.jpg\n",
      "Volvo V60 2018.jpg\n",
      "Volvo V60 Cross Country 2020.jpg\n",
      "Volvo V70 2017.jpg\n",
      "Volvo V90 2016.jpg\n",
      "Volvo XC40 2018.jpg\n",
      "Volvo XC40 Recharge 2021.jpg\n",
      "Volvo XC60 2015.jpg\n",
      "Volvo XC90 2015.jpg\n",
      "Volvo XC90 Recharge 2023.jpg\n",
      "XPeng G3 2019.jpg\n",
      "XPeng G9 2023.jpg\n",
      "XPeng P5 2021.jpg\n",
      "XPeng P7 2020.jpg\n",
      "XPeng P9 2022.jpg\n",
      "done\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Read the first CSV file\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasets/ViT_car_features.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Read the second CSV file\u001b[39;00m\n\u001b[0;32m     56\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatasets/raw/CarsWithStocksPrices.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import csv\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "import pandas as pd\n",
    "\n",
    "def encode_image(image_path, feature_extractor, model):\n",
    "    image = Image.open(image_path)\n",
    "    image = F.resize(image, (224, 224))  \n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    image_encoding = outputs.last_hidden_state[:, 0, :]\n",
    "    return image_encoding.flatten().tolist()\n",
    "\n",
    "def encode_images_in_folder(input_folder, output_csv):\n",
    "    # Load pre-trained ViT model and feature extractor\n",
    "    feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "    model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "    model.eval()\n",
    "\n",
    "    # Get list of all image files in input folder\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "\n",
    "    # Encode images and collect encodings\n",
    "    image_encodings = []\n",
    "    for image_file in image_files:\n",
    "        print(image_file)\n",
    "        image_path = os.path.join(input_folder, image_file)\n",
    "        encoding = encode_image(image_path, feature_extractor, model)\n",
    "        image_encodings.append([image_file] + encoding)\n",
    "\n",
    "    # Transpose the list so that each feature occupies a separate column\n",
    "    transposed_encodings = list(zip(*image_encodings))\n",
    "\n",
    "    # Write encodings to CSV\n",
    "    with open(output_csv, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        # Write header\n",
    "        csv_writer.writerow(['CarName'] + [f'Feature_{i}' for i in range(len(transposed_encodings) - 1)])\n",
    "        # Write rows\n",
    "        for row in zip(*transposed_encodings):\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "# Example usage:\n",
    "input_folder = \"images\"\n",
    "output_csv = \"Datasets/ViT_car_features.csv\"\n",
    "encode_images_in_folder(input_folder, output_csv)\n",
    "print(\"done\")\n",
    "\n",
    "# Read the first CSV file\n",
    "df1 = pd.read_csv(\"Datasets/ViT_car_features.csv\")\n",
    "\n",
    "# Read the second CSV file\n",
    "df2 = pd.read_csv('Datasets/raw/CarsWithStocksPrices.csv')\n",
    "\n",
    "# Merge the dataframes based on the \"Full Name\" column\n",
    "merged_df = pd.merge(df1, df2, on=\"CarName\", how=\"left\")\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_df.to_csv(\"Datasets/ViT_car_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4378f710-6a67-4cb2-8eeb-ad0f0e1565c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first CSV file\n",
    "df1 = pd.read_csv(\"Datasets/ViT_car_features.csv\")\n",
    "\n",
    "# Read the second CSV file\n",
    "df2 = pd.read_csv('Datasets/raw/CarsWithStocksPrices.csv')\n",
    "\n",
    "# Merge the dataframes based on the \"Full Name\" column\n",
    "merged_df = pd.merge(df1, df2, on=\"CarName\", how=\"left\")\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_df.to_csv(\"Datasets/ViT_car_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f702a12-4282-4769-9613-783ae549479d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f3ae1a-c789-400f-a93f-d864164c2f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da1838a4-02c1-45e3-ba86-3711e3849b63",
   "metadata": {},
   "source": [
    "# Predict Stock price using HOG Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3d747a-8ae9-45a6-bddb-df9ba239112b",
   "metadata": {},
   "source": [
    "First apply PCA to reduce dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b45d3e6d-a361-422a-bda8-99abef4e35e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded with shape: (397, 771)\n",
      "Performing PCA to reduce dimensions to 199...\n",
      "Creating DataFrame with the first 5 columns and principal components...\n",
      "Saving the new dataset to Datasets/ViT_car_featuresPCA.csv...\n",
      "Process completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the dataset\n",
    "input_csv = 'Datasets/ViT_car_features.csv'\n",
    "output_csv = 'Datasets/ViT_car_featuresPCA.csv'\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv(input_csv)\n",
    "print(f\"Dataset loaded with shape: {df.shape}\")\n",
    "\n",
    "# Separating out the features for PCA (starting from the 5th column to the end)\n",
    "X = df.iloc[:, 3:].values\n",
    "\n",
    "# Perform PCA\n",
    "n_components = 199  # Adjust the number of components based on your needs\n",
    "print(f\"Performing PCA to reduce dimensions to {n_components}...\")\n",
    "pca = PCA(n_components=n_components)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "\n",
    "# Creating a DataFrame with the first 5 columns and the principal components\n",
    "print(\"Creating DataFrame with the first 5 columns and principal components...\")\n",
    "principalDf = pd.DataFrame(data=principalComponents, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "\n",
    "# Combine the first 5 columns with the principal components\n",
    "result_df = pd.concat([df.iloc[:, :3], principalDf], axis=1)\n",
    "\n",
    "# Saving the new dataset to a CSV file\n",
    "print(f\"Saving the new dataset to {output_csv}...\")\n",
    "result_df.to_csv(output_csv, index=False)\n",
    "print(\"Process completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a7d6a-245c-4097-8ec0-9ca411393199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc21ba07-7f72-4f8f-9452-ad695fa954d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0861573-7cac-44b6-9f5c-a2f40aa74441",
   "metadata": {},
   "source": [
    "Predict Stock price using Machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed338735-b527-41a0-b05d-b6ef28194262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardization complete. The standardized data has been saved to 'Standardized_Dataset.csv' in the 'Datasets/ViT' directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('Datasets/ViT_car_featuresPCA.csv')\n",
    "\n",
    "# Identify the numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize all numerical columns\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Specify the directory to save the file\n",
    "output_directory = 'Datasets/ViT'\n",
    "os.makedirs(output_directory, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# Save the standardized DataFrame to a new CSV file\n",
    "output_file = os.path.join(output_directory, 'ViT_car_featuresPCAstand.csv')\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Standardization complete. The standardized data has been saved to 'Standardized_Dataset.csv' in the '{}' directory.\".format(output_directory))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72586b9b-d7d0-43e2-991e-8cf358f9349b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ViT_car_featuresPCAstand.csv\n",
      "Cross-Validation MSE (Linear Regression): 1.4709974842479585\n",
      "Cross-Validation MSE (XGBoost Regression): 0.8466982810229509\n",
      "Cross-Validation MSE (Random Forest Regression): 0.8800910970506587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation MSE (Neural Network Regression): 0.17451017184648662\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Function to perform Linear Regression with Cross-Validation\n",
    "def perform_linear_regression_cv(df):\n",
    "    X = df.drop(columns=['Price'])  # Features\n",
    "    y = df['Price']  # Target variable\n",
    "\n",
    "    # Linear Regression with Cross-Validation\n",
    "    linear_reg = LinearRegression()\n",
    "    mse_scores = -cross_val_score(linear_reg, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    return mse_scores.mean()\n",
    "\n",
    "# Function to perform XGBoost Regression with Cross-Validation\n",
    "def perform_xgboost_regression_cv(df):\n",
    "    X = df.drop(columns=['Price'])  # Features\n",
    "    y = df['Price']  # Target variable\n",
    "\n",
    "    # Best parameters for XGBoost Regression\n",
    "    best_params = {\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 3,\n",
    "        'n_estimators': 100,\n",
    "        'subsample': 0.8\n",
    "    }\n",
    "\n",
    "    # XGBoost Regression with Cross-Validation\n",
    "    xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', **best_params)\n",
    "    mse_scores = -cross_val_score(xgb_reg, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    return mse_scores.mean()\n",
    "\n",
    "# Function to perform Random Forest Regression with Cross-Validation\n",
    "def perform_random_forest_regression_cv(df):\n",
    "    X = df.drop(columns=['Price'])  # Features\n",
    "    y = df['Price']  # Target variable\n",
    "\n",
    "    # Random Forest Regression with Cross-Validation\n",
    "    rf_reg = RandomForestRegressor(random_state=42)\n",
    "    mse_scores = -cross_val_score(rf_reg, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    return mse_scores.mean()\n",
    "\n",
    "# Function to perform Neural Network Regression with Cross-Validation\n",
    "def perform_neural_network_regression_cv(df):\n",
    "    X = df.drop(columns=['Price'])  # Features\n",
    "    y = df['Price']  # Target variable\n",
    "    \n",
    "    # Define the neural network architecture\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=[X.shape[1]]),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Define K-fold cross-validation\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    mse_scores = []\n",
    "    \n",
    "    # Perform K-fold cross-validation\n",
    "    for train_idx, val_idx in kfold.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "        \n",
    "        # Evaluate the model on the validation set\n",
    "        val_loss = model.evaluate(X_val, y_val, verbose=0)\n",
    "        mse_scores.append(val_loss)\n",
    "    \n",
    "    return np.mean(mse_scores)\n",
    "\n",
    "# Folder containing individual CSV files\n",
    "folder_path = \"Datasets/ViT/test\"\n",
    "\n",
    "# Function to perform data preprocessing and feature engineering\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# Function to preprocess data with enhanced feature engineering and encoding\n",
    "def preprocess_data(df):\n",
    "       \n",
    "    # Drop original 'Date' and 'Quarter_Date' columns\n",
    "    df.drop(columns=['CarName'], inplace=True)\n",
    "\n",
    "    # Use target encoding for the 'Stock' column\n",
    "    encoder = TargetEncoder()\n",
    "    df['Stock_Encoded'] = encoder.fit_transform(df['Stock'], df['Price'])\n",
    "\n",
    "    # Drop the original 'Stock' column\n",
    "    df.drop(columns=['Stock'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Iterate over CSV files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        print(\"Processing file:\", filename)\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Preprocess data\n",
    "        df = preprocess_data(df)\n",
    "        \n",
    "        # Assuming 'Price' is the target column\n",
    "        if 'Price' in df.columns:\n",
    "            # Perform Linear Regression with Cross-Validation\n",
    "            linear_reg_cv_mse = perform_linear_regression_cv(df)\n",
    "            print(\"Cross-Validation MSE (Linear Regression):\", linear_reg_cv_mse)\n",
    "            \n",
    "            # Perform XGBoost Regression with Cross-Validation\n",
    "            xgb_reg_cv_mse = perform_xgboost_regression_cv(df)\n",
    "            print(\"Cross-Validation MSE (XGBoost Regression):\", xgb_reg_cv_mse)\n",
    "            \n",
    "            # Perform Random Forest Regression with Cross-Validation\n",
    "            rf_reg_cv_mse = perform_random_forest_regression_cv(df)\n",
    "            print(\"Cross-Validation MSE (Random Forest Regression):\", rf_reg_cv_mse)\n",
    "            \n",
    "            # Perform Neural Network Regression with Cross-Validation\n",
    "            nn_reg_cv_mse = perform_neural_network_regression_cv(df)\n",
    "            print(\"Cross-Validation MSE (Neural Network Regression):\", nn_reg_cv_mse)\n",
    "        else:\n",
    "            print(\"Error: 'Price' column not found in\", filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30674ef-398f-482a-90ba-7c2d1ff07940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca350d79-fe67-49fa-8678-489eed547826",
   "metadata": {},
   "outputs": [],
   "source": [
    "Processing file: ViT_car_featuresPCAstand.csv\n",
    "Cross-Validation MSE (Linear Regression): 1.4709974842479585\n",
    "Cross-Validation MSE (XGBoost Regression): 0.8466982810229509\n",
    "Cross-Validation MSE (Random Forest Regression): 0.8800910970506587\n",
    "D:\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "Cross-Validation MSE (Neural Network Regression): 0.2712056694552302"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dac961-7ff2-407f-85d6-6c38739d1166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf92014-8a24-4e90-a34c-3b046b503ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd688d-eb6c-42e6-b5a0-5ae790b8d8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff634930-5846-47c9-b1b6-2899c70ff73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df39841-af3d-456e-937f-5de74cdecdf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ab1c0-043a-4008-b95a-a938b0a6ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "\n",
    "# Function to perform Random Forest Regression with Cross-Validation\n",
    "def perform_random_forest_regression_cv(df):\n",
    "    X = df.drop(columns=['Price'])  # Features\n",
    "    y = df['Price']  # Target variable\n",
    "\n",
    "    # Random Forest Regression with Cross-Validation\n",
    "    rf_reg = RandomForestRegressor(random_state=42)\n",
    "    mse_scores = -cross_val_score(rf_reg, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    return mse_scores.mean()\n",
    "\n",
    "\n",
    "\n",
    "# Folder containing individual CSV files\n",
    "folder_path = \"Datasets/ViT\"\n",
    "\n",
    "# Function to perform data preprocessing and feature engineering\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# Function to preprocess data with enhanced feature engineering and encoding\n",
    "def preprocess_data(df):\n",
    "       \n",
    "    # Drop original 'Date' and 'Quarter_Date' columns\n",
    "    df.drop(columns=['CarName'], inplace=True)\n",
    "\n",
    "    # Use target encoding for the 'Stock' column\n",
    "    encoder = TargetEncoder()\n",
    "    df['Stock_Encoded'] = encoder.fit_transform(df['Stock'], df['Price'])\n",
    "\n",
    "    # Drop the original 'Stock' column\n",
    "    df.drop(columns=['Stock'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Iterate over CSV files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        print(\"Processing file:\", filename)\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Preprocess data\n",
    "        df = preprocess_data(df)\n",
    "        \n",
    "        # Assuming 'Price' is the target column\n",
    "        if 'Price' in df.columns:\n",
    "\n",
    "            \n",
    "            # Perform Random Forest Regression with Cross-Validation\n",
    "            rf_reg_cv_mse = perform_random_forest_regression_cv(df)\n",
    "            print(\"Cross-Validation MSE (Random Forest Regression):\", rf_reg_cv_mse)\n",
    "\n",
    "            print(\"Cross-Validation MSE (Neural Network Regression):\", nn_reg_cv_mse)\n",
    "        else:\n",
    "            print(\"Error: 'Price' column not found in\", filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f1f3b-99bd-407e-89c8-4263a48453c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e91cf3-3d9d-46fd-b2a0-39ee0df188ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "285c9b38-01ed-4a5a-9383-84c7ceb08e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ViT_car_featuresPCAstand.csv\n",
      "Best parameters found: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best mean squared error found: 0.8765726919555634\n",
      "Cross-Validation MSE (Random Forest Regression with Grid Search): 0.8765726919555634\n"
     ]
    }
   ],
   "source": [
    "# Function to perform Random Forest Regression with Cross-Validation and Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def perform_random_forest_regression_cv_with_grid_search(df):\n",
    "    X = df.drop(columns=['Price'])  # Features\n",
    "    y = df['Price']  # Target variable\n",
    "\n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "\n",
    "    # Random Forest Regression with Cross-Validation and Grid Search\n",
    "    rf_reg = RandomForestRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=rf_reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Print the best parameters found\n",
    "    print(\"Best parameters found:\", grid_search.best_params_)\n",
    "\n",
    "    # Print the best mean squared error found\n",
    "    print(\"Best mean squared error found:\", -grid_search.best_score_)\n",
    "\n",
    "    return -grid_search.best_score_\n",
    "\n",
    "# Iterate over CSV files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        print(\"Processing file:\", filename)\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Preprocess data\n",
    "        df = preprocess_data(df)\n",
    "        \n",
    "        # Assuming 'Price' is the target column\n",
    "        if 'Price' in df.columns:\n",
    "            # Perform Random Forest Regression with Cross-Validation and Grid Search\n",
    "            rf_reg_cv_mse = perform_random_forest_regression_cv_with_grid_search(df)\n",
    "            print(\"Cross-Validation MSE (Random Forest Regression with Grid Search):\", rf_reg_cv_mse)\n",
    "        else:\n",
    "            print(\"Error: 'Price' column not found in\", filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ebe070-aae1-4a7e-9f73-fa5994baed29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d10a3e-f944-4404-ba1c-5354f69d8011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6dc331-fc20-4584-b7d0-620d5f2f77e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee03491-be89-4348-b43d-361ccca9122e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "383748da-2a96-45a0-90dd-59e163f1cedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset saved as 'dataset2_with_date.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "dataset2 = pd.read_csv('Datasets/ViT/ViT_car_featuresPCAstand.csv')\n",
    "dataset1 = pd.read_csv('Datasets/raw/CarsWithStocksPrices.csv')\n",
    "\n",
    "# Extract 'CarName' and 'Date' columns from dataset1\n",
    "date_info = dataset1[['CarName', 'Date']]\n",
    "\n",
    "# Merge the date_info with dataset2 based on 'CarName'\n",
    "dataset2_with_date = pd.merge(dataset2, date_info, on='CarName', how='left')\n",
    "\n",
    "dataset2_with_date = dataset2_with_date.drop_duplicates(subset='CarName')\n",
    "\n",
    "# Save the new dataset to a CSV file\n",
    "dataset2_with_date.to_csv('dataset2_with_date.csv', index=False)\n",
    "\n",
    "print(\"New dataset saved as 'dataset2_with_date.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924a1b21-31b3-46f1-8de7-d7045dcae16f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
